{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FlairEmbeddingTraining.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_O5AFSI--j_V",
        "colab_type": "text"
      },
      "source": [
        "# Training a Flair Language Model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjRfOBUpDGzI",
        "colab_type": "text"
      },
      "source": [
        "#### Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hPJQQIpoG6K8",
        "colab": {}
      },
      "source": [
        "# Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0GbVu-5Cx1M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install flair --quiet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHS2J4LLCReP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PATHS\n",
        "from pathlib import Path\n",
        "\n",
        "base_path = Path('/gdrive/My Drive/embeddings-comparison/resources')\n",
        "corpus_path = base_path/'corpora'/'text_corpora'\n",
        "model_path = base_path/'models'/'embeddings'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4xU2UMJ6BPR",
        "colab_type": "text"
      },
      "source": [
        "#### TextCorpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgDPjZ0GN6XS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from flair.data import Dictionary\n",
        "from flair.models import LanguageModel\n",
        "from flair.trainers.language_model_trainer import TextCorpus\n",
        "\n",
        "# are you training a forward or backward LM?\n",
        "is_forward_lm = True\n",
        "\n",
        "# load the default character dictionary\n",
        "dictionary = Dictionary.load('chars')\n",
        "\n",
        "# corpus folder with train splits, test and valid\n",
        "corpus_folder = corpus_path/'EXAMPLE-CORPUS'\n",
        "\n",
        "# initialize corpus\n",
        "corpus = TextCorpus(corpus_folder,\n",
        "                    dictionary,\n",
        "                    is_forward_lm,\n",
        "                    character_level=True,\n",
        "                    random_case_flip=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_C1IBTOPTNUU",
        "colab_type": "text"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMNoerT-qFba",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from flair.trainers.language_model_trainer import LanguageModelTrainer\n",
        "\n",
        "# model folder\n",
        "model_folder = model_path/'FLAIR'/'EXAMPLE-MODEL-forward'\n",
        "\n",
        "# option to continue training from checkpoint\n",
        "continue_training = False\n",
        "\n",
        "if not continue_training:\n",
        "    # instantiate your language model, set hidden size and number of layers\n",
        "    language_model = LanguageModel(dictionary,\n",
        "                                   is_forward_lm,\n",
        "                                   hidden_size=1024,\n",
        "                                   nlayers=1)\n",
        "\n",
        "    trainer = LanguageModelTrainer(language_model, corpus)\n",
        "\n",
        "else:\n",
        "    checkpoint = model_folder/'checkpoint.pt'\n",
        "    trainer = LanguageModelTrainer.load_from_checkpoint(checkpoint, corpus)\n",
        "\n",
        "\n",
        "trainer.log_interval = 500\n",
        "trainer.train(model_folder,\n",
        "              sequence_length=250,\n",
        "              mini_batch_size=32,\n",
        "              max_epochs=10,\n",
        "              learning_rate=20.0,\n",
        "              patience=10,\n",
        "              checkpoint=True,\n",
        "              num_workers=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oepXdj6oi5Bu",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "# Fine-Tuning an Existing Language Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5ozeR_lMTAEx"
      },
      "source": [
        "#### Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m_d4fHflTAE2",
        "colab": {}
      },
      "source": [
        "# Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EvxuXwhbTAE-",
        "colab": {}
      },
      "source": [
        "!pip install flair --quiet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8fAmnYjHTAFB",
        "colab": {}
      },
      "source": [
        "# PATHS\n",
        "from pathlib import Path\n",
        "\n",
        "base_path = Path('/gdrive/My Drive/embeddings-comparison/resources')\n",
        "corpus_path = base_path/'corpora'/'text_corpora'\n",
        "model_path = base_path/'models'/'embeddings'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fi7GWd-qTCWE",
        "colab_type": "text"
      },
      "source": [
        "#### Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VS-JKXB8kujU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from flair.data import Dictionary\n",
        "from flair.embeddings import FlairEmbeddings\n",
        "from flair.trainers.language_model_trainer import LanguageModelTrainer, TextCorpus\n",
        "\n",
        "\n",
        "# instantiate an existing LM, such as one from the FlairEmbeddings\n",
        "language_model = FlairEmbeddings('de-forward').lm\n",
        "\n",
        "# are you fine-tuning a forward or backward LM?\n",
        "is_forward_lm = language_model.is_forward_lm\n",
        "\n",
        "# get the dictionary from the existing language model\n",
        "dictionary: Dictionary = language_model.dictionary\n",
        "\n",
        "# corpus folder with train splits, test and valid\n",
        "corpus_folder = corpus_path/'example-corpus'\n",
        "\n",
        "# initialize Corpus\n",
        "corpus = TextCorpus(corpus_folder,\n",
        "                    dictionary,\n",
        "                    is_forward_lm,\n",
        "                    character_level=True)\n",
        "\n",
        "# use the model trainer to fine-tune this model on your corpus\n",
        "trainer = LanguageModelTrainer(language_model, corpus)\n",
        "\n",
        "# model folder\n",
        "model_folder = model_path/'FLAIR'/'de-forward-finetuned'\n",
        "\n",
        "trainer.train(model_folder,\n",
        "              sequence_length=100,\n",
        "              mini_batch_size=100,\n",
        "              learning_rate=20,\n",
        "              patience=10,\n",
        "              checkpoint=True)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}