{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextClassifierTraining_CrossVal.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_O5AFSI--j_V",
        "colab_type": "text"
      },
      "source": [
        "# Training a Text Classification Model with Cross-Validation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkVtxK79931X",
        "colab_type": "text"
      },
      "source": [
        "#### Google Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SZE0ei290dx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MOUNT GOOGLE DRIVE\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b-gkSTE-NLS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# INSTALL FLAIR\n",
        "!pip install flair==0.4.4 --quiet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0CoU6IR-Q0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# INSTALL ALLENNLP (only necessary when using ELMoEmbeddings)\n",
        "#!pip install allennlp --quiet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsZth3cH-i_j",
        "colab_type": "text"
      },
      "source": [
        "#### Paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIVdfJ4X-mTC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SETUP PATHS\n",
        "from pathlib import Path\n",
        "\n",
        "base_path = Path('/gdrive/My Drive/embeddings-comparison/resources')\n",
        "emb_path = base_path/'models'/'embeddings'\n",
        "cls_model_path = base_path/'models'/'classifiers'\n",
        "cls_corpus_path = base_path/'corpora'/'classification_corpora'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_KBsrLCMIIN",
        "colab_type": "text"
      },
      "source": [
        "#### ClassificationCorpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leIe8mRRj7Ld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from flair.data import Corpus\n",
        "from flair.datasets import  ClassificationCorpus #TREC_6\n",
        "\n",
        "# this is the folder in which train, test and dev files reside\n",
        "corpus_folder = cls_corpus_path/'EXAMPLE-CORPUS'\n",
        "\n",
        "# get the corpus\n",
        "corpus = ClassificationCorpus(corpus_folder)\n",
        "print(corpus)\n",
        "\n",
        "# create the label dictionary\n",
        "label_dict = corpus.make_label_dictionary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uj3C3z6B_8mT",
        "colab_type": "text"
      },
      "source": [
        "#### Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-yBG6yf14Ew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# INITIALIZE EMBEDDINGS\n",
        "from flair.embeddings import FlairEmbeddings, DocumentRNNEmbeddings, WordEmbeddings, BertEmbeddings, ELMoEmbeddings\n",
        "\n",
        "'''\n",
        "# WordEmbeddings [word2vec, fastText, glove]\n",
        "# we = str(emb_path/'example.kv')\n",
        "\n",
        "# FlairEmbeddings\n",
        "# flair_fwd = emb_path/'FLAIR'/'example-fwd.pt'\n",
        "# flair_bwd = emb_path/'FLAIR'/'example-bwd.pt'\n",
        "\n",
        "# ELMoEmbeddings\n",
        "# elmo_opttions = emb_path/'ELMO'/'options.json'\n",
        "# elmo_weights = emb_path/'ELMO'/'weights.hdf5'\n",
        "\n",
        "# BertEmbeddings\n",
        "# bert = str(emb_path/'BERT'/'model_folder')\n",
        "\n",
        "# List of Embeddings\n",
        "embeddings = [#WordEmbeddings(we),\n",
        "              #FlairEmbeddings(flair_fwd),\n",
        "              #FlairEmbeddings(flair_bwd),\n",
        "              #ELMoEmbeddings(elmo_options, elmo_weights),\n",
        "              #BertEmbeddings(bert),\n",
        "             ])\n",
        "             \n",
        "# DocumentRNNEmbeddings\n",
        "# Can choose between RNN types (GRU by default, or LSTM)\n",
        "document_embeddings = DocumentRNNEmbeddings(embeddings,\n",
        "                                            hidden_size=512,\n",
        "                                            reproject_words=True,\n",
        "                                            reproject_words_dimension=256,\n",
        "                                           )\n",
        "\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoVB817PPFNy",
        "colab_type": "text"
      },
      "source": [
        "#### Helper Evaluation function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOVLPwwDKIwr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "def result_summary(result):\n",
        "    scores = []\n",
        "    lines = result.detailed_results.split('\\n')\n",
        "    \n",
        "    for line in lines[3:]:\n",
        "        split_line = re.split('\\ -\\ |\\ +|:\\ ', line)\n",
        "        scores.append(split_line)\n",
        "    scores = np.array(scores)\n",
        "    tags = scores[:,0].tolist()\n",
        "    scores_ = scores[:, 2::2]\n",
        "    tag_tfpn = scores_[:, :4].astype(int)\n",
        "    tag_metrics = scores_[:, 4:].astype(float)\n",
        "    metrics = np.array(result.log_line.split('\\t')).astype(float).reshape(1,3)\n",
        "    \n",
        "    df_tag_tfpn = pd.DataFrame(data=tag_tfpn,index=tags,columns=['true-positive','false-positive', 'false-negative', 'true-negative'])\n",
        "    df_tag_metrics = pd.DataFrame(data=tag_metrics,index=tags,columns=['precision','recall', 'accuracy','f1-score'])\n",
        "    df_metrics = pd.DataFrame(data=metrics, index=None,columns=['precision','recall','f1-score'])\n",
        "    \n",
        "    return df_tag_tfpn, df_tag_metrics, df_metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEZRrn9zGAAO",
        "colab_type": "text"
      },
      "source": [
        "#### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuNooAy-Icgq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from flair.datasets import DataLoader, SentenceDataset\n",
        "from flair.models import TextClassifier\n",
        "from flair.trainers import ModelTrainer\n",
        "import pickle\n",
        "\n",
        "\n",
        "# Set number of splits\n",
        "kf = KFold(n_splits=5)\n",
        "\n",
        "# All sentences\n",
        "complete_corpus = corpus.get_all_sentences()\n",
        "\n",
        "# Cross-Validation\n",
        "i=1\n",
        "for train_index, test_index in kf.split(complete_corpus):\n",
        "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
        "    print(\"Fold:\", i)\n",
        "    corpus._train = SentenceDataset([complete_corpus[j] for j in train_index])\n",
        "    corpus._test = SentenceDataset([complete_corpus[j] for j in test_index])\n",
        "    corpus._dev = SentenceDataset([complete_corpus[j] for j in test_index])\n",
        "    print(corpus)\n",
        "    \n",
        "    \n",
        "    # 5. create the text classifier\n",
        "    classifier = TextClassifier(document_embeddings, label_dictionary=label_dict)\n",
        "    \n",
        "    # Initialize ModelTrainer\n",
        "    trainer = ModelTrainer(classifier, corpus)\n",
        "    # Define output path\n",
        "    model_folder = cls_model_path/'EXAMPLE-MODEL'\n",
        "    \n",
        "    # Training\n",
        "    trainer.train(model_folder,\n",
        "                  learning_rate=0.2,\n",
        "                  mini_batch_size=32,\n",
        "                  anneal_factor=0.5,\n",
        "                  patience=5,\n",
        "                  max_epochs=50,\n",
        "                  train_with_dev=False,\n",
        "                  shuffle=True,\n",
        "                  save_final_model=True,\n",
        "                  embeddings_storage_mode='gpu')\n",
        "    \n",
        "    \n",
        "    # Evaluation\n",
        "    result, eval_loss = trainer.model.evaluate(DataLoader(trainer.corpus.test,\n",
        "                                                          batch_size=8,\n",
        "                                                          num_workers=4))\n",
        "    # tag_tfpn, tag_metrics, metrics\n",
        "    if i==1:\n",
        "        tt, tm, m = result_summary(result)\n",
        "    else:\n",
        "        tt_, tm_, m_ = result_summary(result)\n",
        "        tt = tt.append(tt_)\n",
        "        tm = tm.append(tm_)\n",
        "        m = m.append(m_)\n",
        "    \n",
        "    i+=1  \n",
        "    \n",
        "df = tt.groupby(tt.index).sum()\n",
        "tag_metrics_avg = tm.groupby(tm.index).mean()\n",
        "summary = m.mean()\n",
        "    \n",
        "df['precision'] = df['true-positive'] / (df['true-positive'] + df['false-positive'])\n",
        "df['recall'] = df['true-positive'] / (df['true-positive'] + df['false-negative'])\n",
        "df['accuracy'] = df['true-positive'] / (df['true-positive'] + df['false-positive'] + df['false-negative'])\n",
        "df['f1-score'] = 2*df['precision']*df['recall'] / (df['precision'] + df['recall'])\n",
        "    \n",
        "# pickle dump\n",
        "pickle.dump(df,(model_folder/'details.pkl').open(mode='wb'))\n",
        "pickle.dump(tag_metrics_avg,(model_folder/'tag_metrics_avg.pkl').open(mode='wb'))\n",
        "pickle.dump(summary,(model_folder/'summary.pkl').open(mode='wb'))\n",
        "\n",
        "print(summary)\n",
        "print('\\n-------------------------------------------------------------------\\n')\n",
        "print(df)\n",
        "print('\\n-------------------------------------------------------------------\\n')\n",
        "print(tag_metrics_avg)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}